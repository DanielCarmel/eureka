# LLM Engine Configuration

# Model configuration
model:
  path: "/app/models/mistral-7b-instruct.gguf"
  type: "llama"
  max_tokens: 512
  temperature: 0.7
  top_p: 0.95

# Server configuration
server:
  host: "0.0.0.0"
  port: 8080
  api_version: "v1"
  api_key: ""  # Set to empty string to disable authentication

# GPU settings
gpu:
  use_gpu: true
  gpu_layers: 64
  precision: "float16"

# Logging configuration
logging:
  level: "INFO"
  file: "logs/llm-engine.log"
  max_size_mb: 10
  backup_count: 5
